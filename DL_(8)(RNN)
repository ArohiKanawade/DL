
import numpy as np

# --- Step 1: Data Preparation ---
X = np.array([[i] for i in range(10)], dtype=float)   # 0 to 9
y = np.array([[i + 1] for i in range(10)], dtype=float)  # 1 to 10

# Normalize 
X = X / 10
y = y / 10

# --- Step 2: Parameters ---
input_size = 1
hidden_size = 2
output_size = 1

Wxh = np.random.randn(hidden_size, input_size) * 0.01
Whh = np.random.randn(hidden_size, hidden_size) * 0.01
Why = np.random.randn(output_size, hidden_size) * 0.01
bh = np.zeros((hidden_size, 1))
by = np.zeros((output_size, 1))

def tanh(x): return np.tanh(x)
def dtanh(x): return 1 - np.tanh(x)**2

# --- Step 3: Training ---
learning_rate = 0.05
epochs = 5000

for epoch in range(epochs):
    total_loss = 0
    h_prev = np.zeros((hidden_size, 1))
    for i in range(len(X)):
        x = np.array([[X[i][0]]])
        target = np.array([[y[i][0]]])

        # Forward pass
        h_current = tanh(np.dot(Wxh, x) + np.dot(Whh, h_prev) + bh)
        y_pred = np.dot(Why, h_current) + by

        # Loss
        loss = (y_pred - target)**2
        total_loss += loss.item()

        # Backpropagation
        dy = 2 * (y_pred - target)
        dWhy = np.dot(dy, h_current.T)
        dby = dy

        dh = np.dot(Why.T, dy) * dtanh(h_current)
        dWxh = np.dot(dh, x.T)
        dWhh = np.dot(dh, h_prev.T)
        dbh = dh

        # Update weights
        Wxh -= learning_rate * dWxh
        Whh -= learning_rate * dWhh
        Why -= learning_rate * dWhy
        bh -= learning_rate * dbh
        by -= learning_rate * dby

        h_prev = h_current

    if epoch % 500 == 0:
        print(f"Epoch {epoch}, Loss: {total_loss:.6f}")

# --- Step 4: Predictions ---
print("\nPredictions (de-normalized):")
h_test = np.zeros((hidden_size, 1))
for test_val in [4, 5, 6, 7, 8]:
    x = np.array([[test_val / 10]])  # normalize input
    h_test = tanh(np.dot(Wxh, x) + np.dot(Whh, h_test) + bh)
    y_pred = np.dot(Why, h_test) + by
    print(f"Input: {test_val}, Predicted next number: {y_pred.item() * 10:.2f}")
Epoch 0, Loss: 2.019210
Epoch 500, Loss: 0.000724
Epoch 1000, Loss: 0.000386
Epoch 1500, Loss: 0.000252
Epoch 2000, Loss: 0.000175
Epoch 2500, Loss: 0.000126
Epoch 3000, Loss: 0.000095
Epoch 3500, Loss: 0.000074
Epoch 4000, Loss: 0.000059
Epoch 4500, Loss: 0.000050

Predictions (de-normalized):
Input: 4, Predicted next number: 4.97
Input: 5, Predicted next number: 6.01
Input: 6, Predicted next number: 7.03
Input: 7, Predicted next number: 8.03
Input: 8, Predicted next number: 9.01
import numpy as np
x = np.array([[i] for i in range(10)], dtype=float)
y = np.array([[i] for i in range(1,11)], dtype=float)
x= x/10
y = y/10
input_size =1
hidden_size=2
output_size=1

wxh = np.random.rand(hidden_size, input_size)*0.01
whh = np.random.rand(hidden_size, hidden_size)*0.01
why = np.random.rand(output_size, hidden_size)*0.01
bh = np.zeros((hidden_size, 1))
by = np.zeros((output_size,1))
def tanh(x):
    return np.tanh(x)


def dtanh(x):
    return 1-np.tanh(x)**2
learning_rate =0.05
epochs =5000
for epoch in range(epochs):
    total_loss = 0
    h_prev = np.zeros((hidden_size, 1))
    for i in range(len(x)):
        x = np.array([[x[i][0]]])
        target = np.array([[y[i][0]]])
 
